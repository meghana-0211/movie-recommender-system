{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOcwn8hOa0E2qs5cZvzybpx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"o86JA1jG2B9b","executionInfo":{"status":"ok","timestamp":1732899336311,"user_tz":-330,"elapsed":5277,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"outputs":[],"source":["import re\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n","from sklearn.impute import SimpleImputer\n","from imblearn.over_sampling import SMOTE\n"]},{"cell_type":"code","source":["class DataPreprocessor:\n","    def __init__(self, config):\n","        self.config = config\n","    RAW_DATA_PATH = '/content/bollywood_data_set.csv'\n","\n","    def load_data(self):\n","        df = pd.read_csv(self.config.RAW_DATA_PATH)\n","        return df"],"metadata":{"id":"yV9Jj34b2XT9","executionInfo":{"status":"ok","timestamp":1732899744335,"user_tz":-330,"elapsed":482,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["    def _extract_year(self, text):\n","\n","        text = str(text)\n","        # Try extracting year from parentheses\n","        parentheses_match = re.search(r'\\((\\d{4})\\)', text)\n","        if parentheses_match:\n","            return int(parentheses_match.group(1))\n","\n","        # Try extracting year with hyphen\n","        hyphen_match = re.search(r'-(\\d{4})', text)\n","        if hyphen_match:\n","            return int(hyphen_match.group(1))\n","\n","        # Try direct year match\n","        direct_match = re.search(r'\\b(\\d{4})\\b', text)\n","        if direct_match:\n","            return int(direct_match.group(1))\n","\n","        # If no year found, return NaN\n","        return np.nan\n",""],"metadata":{"id":"Z9GCJtG42eL9","executionInfo":{"status":"ok","timestamp":1732899378517,"user_tz":-330,"elapsed":375,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["    def _encode_categorial(self, series, delimiter=None, top_n=50):\n","        if delimiter:\n","            series= series.str.split(delimiter)\n","\n","        all_categories = series.explode().value_counts()\n","\n","        top_categories = all_categories.head(top_n).index.tolist()\n","\n","        category_mapping = {cat: idx for idx, cat in enumerate(top_categories)}\n","\n","        def encode_entry(entry):\n","            if isinstance(entry, list):\n","\n","                return [category_mapping.get(cat, -1) for cat in entry if cat in category_mapping]\n","            else:\n","\n","                return category_mapping.get(entry, -1)\n","\n","\n","        encoded = series.apply(encode_entry)\n","\n","        return encoded\n"],"metadata":{"id":"i-YAQ79J2yBs","executionInfo":{"status":"ok","timestamp":1732899461196,"user_tz":-330,"elapsed":386,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["    def preprocess_data(self, df):\n","        \"\"\"Comprehensive data preprocessing\"\"\"\n","        # Clean column names\n","        df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n","\n","        # Extract year from movie name\n","        df['year_of_release'] = df['movie_name'].apply(self._extract_year)\n","\n","        # Clean and convert runtime\n","        df['runtime'] = df['runtime'].astype(str)  # Ensure string type\n","        df['runtime'] = df['runtime'].str.replace(' min', '')  # Remove 'min'\n","        df['runtime'] = pd.to_numeric(df['runtime'], errors='coerce')  # Convert to numeric, invalid entries become NaN\n","\n","        df['no_of_votes'] = df['no_of_votes'].astype(str).str.replace(',', '').str.strip()\n","\n","    # Convert to numeric, handling errors\n","        df['no_of_votes'] = pd.to_numeric(df['no_of_votes'], errors='coerce')\n","\n","    # Fill NaN values with 0 or another appropriate default\n","        df['no_of_votes'] = df['no_of_votes'].fillna(0).astype(int)\n","\n","\n","        # Handle missing years\n","        current_year = pd.Timestamp.now().year\n","        df['year_of_release'] = df['year_of_release'].apply(\n","            lambda x: x if pd.notnull(x) and 1900 <= x <= current_year else np.nan\n","        )\n","\n","        # Impute missing years with median\n","        median_year = df['year_of_release'].median()\n","        df['year_of_release'] = df['year_of_release'].fillna(median_year)\n","\n","        # Numeric columns for imputation\n","        numeric_columns = ['year_of_release', 'runtime', 'imdb_rating', 'no_of_votes']\n","        text_columns = ['movie_name', 'plot_description', 'director', 'actors']\n","\n","        # Replace empty strings with NaN for numeric columns\n","        for col in numeric_columns:\n","            df[col] = pd.to_numeric(df[col], errors='coerce')\n","\n","        # Numeric imputation using median\n","        numeric_imputer = SimpleImputer(strategy='median')\n","        df[numeric_columns] = numeric_imputer.fit_transform(df[numeric_columns])\n","\n","        # Text column cleaning: Replace NaN with 'Unknown'\n","        for col in text_columns:\n","            df[col] = df[col].fillna('Unknown')\n","            df[col] = df[col].str.strip()\n","\n","        # Feature engineering\n","        df['runtime_minutes'] = df['runtime'].astype(float)\n","\n","        # Encode categorical features\n","        df['directors_encoded'] = self._encode_categorical(df['director'])\n","        df['actors_encoded'] = self._encode_categorical(df['actors'], delimiter='|')\n","\n","        # Normalize numeric features\n","        scaler = StandardScaler()\n","        df[['normalized_rating', 'normalized_votes']] = scaler.fit_transform(\n","            df[['imdb_rating', 'no_of_votes']]\n","        )\n","\n","        return df"],"metadata":{"id":"EXJzXWHY21zG","executionInfo":{"status":"ok","timestamp":1732899895553,"user_tz":-330,"elapsed":381,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["    def _encode_categorical(self, series, delimiter=None):\n","        \"\"\"Encode categorical variables\"\"\"\n","        if delimiter:\n","            series = series.str.split(delimiter)\n","\n","        mlb = MultiLabelBinarizer()\n","        encoded = mlb.fit_transform(series)\n","        return encoded\n",""],"metadata":{"id":"LeHkgxCt26aX","executionInfo":{"status":"ok","timestamp":1732899492062,"user_tz":-330,"elapsed":385,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["    def balance_dataset(self, df):\n","        \"\"\"Apply SMOTE for balancing the dataset\"\"\"\n","        X = df[['normalized_rating', 'normalized_votes']]\n","        y = df['imdb_rating']\n","\n","        smote = SMOTE(random_state=42)\n","        X_resampled, y_resampled = smote.fit_resample(X, y)\n","\n","        balanced_df = pd.DataFrame(X_resampled, columns=X.columns)\n","        balanced_df['imdb_rating'] = y_resampled\n","\n","        return balanced_df"],"metadata":{"id":"keIQW78t29Ua","executionInfo":{"status":"ok","timestamp":1732899501073,"user_tz":-330,"elapsed":665,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from transformers import AutoModel, AutoTokenizer"],"metadata":{"id":"1BIg1afI2_ee","executionInfo":{"status":"ok","timestamp":1732899521975,"user_tz":-330,"elapsed":8696,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class TextFeatureExtractor:\n","    def __init__(self, model_name='ai4bharat/indic-bert'):\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n","        self.model = AutoModel.from_pretrained(model_name)\n","\n","    def extract_text_features(self, texts):\n","        \"\"\"Extract deep semantic features from text\"\"\"\n","        inputs = self.tokenizer(\n","            texts,\n","            padding=True,\n","            truncation=True,\n","            max_length=512,\n","            return_tensors='pt'\n","        )\n","\n","        with torch.no_grad():\n","            outputs = self.model(**inputs)\n","\n","        return outputs.last_hidden_state.mean(dim=1)"],"metadata":{"id":"Oo8amjWp3Etr","executionInfo":{"status":"ok","timestamp":1732899535703,"user_tz":-330,"elapsed":370,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class CNNFeatureExtractor(nn.Module):\n","    def __init__(self, input_dim, embedding_dim):\n","        super().__init__()\n","        self.conv1d = nn.Conv1d(\n","            in_channels=input_dim,\n","            out_channels=embedding_dim,\n","            kernel_size=3,\n","            padding=1\n","        )\n","        self.relu = nn.LeakyReLU()\n","        self.pool = nn.MaxPool1d(kernel_size=2)\n","\n","    def forward(self, x):\n","        x = self.conv1d(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","        return x"],"metadata":{"id":"f3pHD-tS3ICm","executionInfo":{"status":"ok","timestamp":1732899548038,"user_tz":-330,"elapsed":404,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["pip install neo4j"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqqPNKH63Ods","executionInfo":{"status":"ok","timestamp":1732899578477,"user_tz":-330,"elapsed":7937,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}},"outputId":"6225deb3-8292-4bec-b1c8-b0066ccdaeba"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting neo4j\n","  Downloading neo4j-5.27.0-py3-none-any.whl.metadata (5.9 kB)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2024.2)\n","Downloading neo4j-5.27.0-py3-none-any.whl (301 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/301.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m297.0/301.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.7/301.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: neo4j\n","Successfully installed neo4j-5.27.0\n"]}]},{"cell_type":"code","source":["from neo4j import GraphDatabase\n","import networkx as nx\n","import numpy as np"],"metadata":{"id":"--nzgRhi3LF9","executionInfo":{"status":"ok","timestamp":1732899582167,"user_tz":-330,"elapsed":1627,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class GraphConstructor:\n","    def __init__(self, config):\n","        self.driver = GraphDatabase.driver(\n","            config.NEO4J_URI,\n","            auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD)\n","        )\n","\n","    def create_movie_graph(self, movies_df):\n","        \"\"\"Construct graph representation of movies\"\"\"\n","        G = nx.Graph()\n","\n","        # Add movie nodes\n","        for _, movie in movies_df.iterrows():\n","            G.add_node(\n","                movie['movie_name'],\n","                type='movie',\n","                rating=movie['imdb_rating'],\n","                year=movie['year_of_release']\n","            )\n","\n","        # Add edges based on similarity\n","        similarity_matrix = self._compute_movie_similarity(movies_df)\n","\n","        for i in range(len(movies_df)):\n","            for j in range(i+1, len(movies_df)):\n","                if similarity_matrix[i, j] > 0.7:  # Similarity threshold\n","                    G.add_edge(\n","                        movies_df.iloc[i]['movie_name'],\n","                        movies_df.iloc[j]['movie_name'],\n","                        weight=similarity_matrix[i, j]\n","                    )\n","\n","        return G\n","\n","    def _compute_movie_similarity(self, movies_df):\n","        \"\"\"Compute cosine similarity between movies\"\"\"\n","        features = movies_df[['normalized_rating', 'normalized_votes']].values\n","\n","        # Cosine similarity\n","        norm = np.linalg.norm(features, axis=1)\n","        similarity = np.dot(features, features.T) / (norm[:, None] * norm[None, :])\n","\n","        return similarity\n","\n","    def save_to_neo4j(self, graph):\n","        \"\"\"Save graph to Neo4j database\"\"\"\n","        with self.driver.session() as session:\n","            # Clear existing data\n","            session.run(\"MATCH (n) DETACH DELETE n\")\n","\n","            # Create movie nodes\n","            for node, data in graph.nodes(data=True):\n","                session.run(\n","                    \"CREATE (m:Movie {name: $name, rating: $rating, year: $year})\",\n","                    name=node,\n","                    rating=data.get('rating', 0),\n","                    year=data.get('year', 0)\n","                )\n","\n","            # Create movie edges\n","            for u, v, data in graph.edges(data=True):\n","                session.run(\n","                    \"MATCH (a:Movie {name: $name1}), (b:Movie {name: $name2}) \"\n","                    \"CREATE (a)-[:SIMILAR {weight: $weight}]->(b)\",\n","                    name1=u, name2=v, weight=data.get('weight', 0)\n","                )"],"metadata":{"id":"9fobev6E3TjO","executionInfo":{"status":"ok","timestamp":1732899612594,"user_tz":-330,"elapsed":393,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import networkx as nx\n","from sklearn.metrics.pairwise import cosine_similarity"],"metadata":{"id":"YF8kEAX33WYO","executionInfo":{"status":"ok","timestamp":1732899625543,"user_tz":-330,"elapsed":400,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class BollywoodRecommender:\n","    def __init__(self, graph, feature_extractor):\n","        self.graph = graph\n","        self.feature_extractor = feature_extractor\n","\n","    def get_recommendations(self, base_movie, top_k=3):\n","        \"\"\"Generate movie recommendations\"\"\"\n","        if base_movie not in self.graph.nodes:\n","            raise ValueError(f\"Movie {base_movie} not found in graph\")\n","\n","        # Content-based similarity\n","        content_candidates = self._content_based_recommendation(base_movie)\n","\n","        # Graph-based recommendation\n","        graph_candidates = self._graph_based_recommendation(base_movie)\n","\n","        # Hybrid recommendation\n","        recommendations = self._merge_recommendations(\n","            content_candidates,\n","            graph_candidates,\n","            top_k\n","        )\n","\n","        return recommendations\n","\n","    def _content_based_recommendation(self, base_movie):\n","        \"\"\"Recommend based on content similarity\"\"\"\n","        candidates = {}\n","        for movie in self.graph.nodes:\n","            if movie != base_movie:\n","                similarity = self._compute_content_similarity(base_movie, movie)\n","                candidates[movie] = similarity\n","\n","        return sorted(candidates.items(), key=lambda x: x[1], reverse=True)\n","\n","    def _graph_based_recommendation(self, base_movie):\n","        \"\"\"Recommend based on graph proximity\"\"\"\n","        # Find movies within 2 hops\n","        candidates = {}\n","        for movie in nx.single_source_shortest_path_length(\n","            self.graph, base_movie, cutoff=2\n","        ).keys():\n","            if movie != base_movie:\n","                candidates[movie] = self.graph[base_movie][movie]['weight']\n","\n","        return sorted(candidates.items(), key=lambda x: x[1], reverse=True)\n","\n","    def _merge_recommendations(self, content_candidates, graph_candidates, top_k):\n","        \"\"\"Merge and re-rank recommendations\"\"\"\n","        merged_candidates = {}\n","\n","        # Weight content and graph recommendations\n","        for movie, score in content_candidates:\n","            merged_candidates[movie] = 0.6 * score\n","\n","        for movie, score in graph_candidates:\n","            merged_candidates[movie] = merged_candidates.get(movie, 0) + 0.4 * score\n","\n","        # Sort and return top K\n","        top_recommendations = sorted(\n","            merged_candidates.items(),\n","            key=lambda x: x[1],\n","            reverse=True\n","        )[:top_k]\n","\n","        return [movie for movie, _ in top_recommendations]\n","\n","    def _compute_content_similarity(self, movie1, movie2):\n","        \"\"\"Compute content similarity between two movies\"\"\"\n","        # This is a placeholder - replace with actual feature comparison\n","        return cosine_similarity(\n","            self.feature_extractor.extract_text_features([movie1]),\n","            self.feature_extractor.extract_text_features([movie2])\n","        )[0][0]"],"metadata":{"id":"dGQsa7vX3hdd","executionInfo":{"status":"ok","timestamp":1732899644134,"user_tz":-330,"elapsed":349,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["\n","# Configuration settings for the recommendation engine\n","class Config:\n","    # Data paths\n","    RAW_DATA_PATH = '/content/bollywood_data_set.csv'\n","    PROCESSED_DATA_PATH = '/content/bollywood_data_set.csv'\n","\n","    # Neo4j Database Configuration\n","    NEO4J_URI = 'bolt://localhost:7687'\n","    NEO4J_USERNAME = 'neo4j'\n","    NEO4J_PASSWORD = '12345678'\n","\n","    # Model Hyperparameters\n","    EMBEDDING_DIM = 128\n","    CNN_FILTER_SIZE = 3\n","    GNN_LAYERS = 2\n","\n","    # Recommendation Parameters\n","    TOP_K_RECOMMENDATIONS = 3\n","    SIMILARITY_THRESHOLD = 0.7\n","\n"],"metadata":{"id":"Y6vYesWu3iaS","executionInfo":{"status":"ok","timestamp":1732899945469,"user_tz":-330,"elapsed":397,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def main():\n","    # Initialize configuration\n","    config = Config()\n","\n","    # Data Preprocessing\n","    preprocessor = DataPreprocessor(config)\n","    raw_data = preprocessor.load_data()\n","    processed_data = preprocessor.preprocess_data(raw_data)\n","    balanced_data = preprocessor.balance_dataset(processed_data)\n","\n","    # Feature Extraction\n","    feature_extractor = TextFeatureExtractor()\n","\n","    # Graph Construction\n","    graph_constructor = GraphConstructor(config)\n","    movie_graph = graph_constructor.create_movie_graph(balanced_data)\n","    graph_constructor.save_to_neo4j(movie_graph)\n","\n","    # Recommendation Engine\n","    recommender = BollywoodRecommender(movie_graph, feature_extractor)\n","\n","    # Example Recommendation\n","    base_movie = \"3 Idiots\"\n","    recommendations = recommender.get_recommendations(base_movie)\n","\n","    print(f\"Recommendations for {base_movie}:\")\n","    for movie in recommendations:\n","        print(movie)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"ZnFxluo33nZU","executionInfo":{"status":"error","timestamp":1732901123107,"user_tz":-330,"elapsed":556,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}},"outputId":"ba9f4764-0769-401b-8b1c-b9c46bc03494"},"execution_count":37,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'DataPreprocessor' object has no attribute 'preprocess_data'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-49ac1183a711>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-37-49ac1183a711>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataPreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mbalanced_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbalance_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataPreprocessor' object has no attribute 'preprocess_data'"]}]},{"cell_type":"code","source":["# Install required packages\n","!pip install torch torchvision torchaudio\n","!pip install dgl dgllife\n","!pip install transformers\n","!pip install neo4j\n","!pip install networkx\n","!pip install scikit-learn\n","!pip install pandas numpy\n","!pip install imblearn\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ci5qfJsr-WSe","executionInfo":{"status":"error","timestamp":1732901938193,"user_tz":-330,"elapsed":31740,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}},"outputId":"816aa105-bcb7-4b2a-b975-22c79e26d4c2"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (2.1.0)\n","Collecting dgllife\n","  Downloading dgllife-0.3.2-py3-none-any.whl.metadata (667 bytes)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.26.4)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.13.1)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.4.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.6)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n","Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.9.0)\n","Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.5.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgllife) (2.2.2)\n","Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (from dgllife) (0.2.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.4.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.8.30)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->dgllife) (3.5.0)\n","Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.5.1+cu121)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.16.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.0.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (3.1.0)\n","Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.10.9.7)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2024.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.12.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (3.0.2)\n","Downloading dgllife-0.3.2-py3-none-any.whl (226 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dgllife\n","Successfully installed dgllife-0.3.2\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: neo4j in /usr/local/lib/python3.10/dist-packages (5.27.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2024.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: imblearn in /usr/local/lib/python3.10/dist-packages (0.0)\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.12.4)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.26.4)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.13.1)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.5.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (3.5.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["UsageError: Line magic function `%%writefile` not found.\n"]}]},{"cell_type":"code","source":["class Config:\n","    # Data paths\n","    RAW_DATA_PATH = '/content/bollywood_recommender/data/bollywood_data_set.csv'\n","    PROCESSED_DATA_PATH = '/content/bollywood_recommender/data/processed_movies.csv'\n","\n","    # Neo4j Database Configuration\n","    NEO4J_URI = 'bolt://localhost:7687'\n","    NEO4J_USERNAME = 'neo4j'\n","    NEO4J_PASSWORD = '12345678'\n","\n","    # Model Hyperparameters\n","    EMBEDDING_DIM = 128\n","    CNN_FILTER_SIZE = 3\n","    GNN_LAYERS = 2\n","\n","    # Recommendation Parameters\n","    TOP_K_RECOMMENDATIONS = 3\n","    SIMILARITY_THRESHOLD = 0.7\n"],"metadata":{"id":"oH7mM6jeB_Ws","executionInfo":{"status":"ok","timestamp":1732902388321,"user_tz":-330,"elapsed":371,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Data Preprocessing\n","\n","import re\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n","from sklearn.impute import SimpleImputer\n","from imblearn.over_sampling import SMOTE\n","\n","class DataPreprocessor:\n","    def __init__(self, config):\n","        self.config = config\n","\n","    def load_data(self):\n","        df = pd.read_csv(self.config.RAW_DATA_PATH)\n","        return df\n","\n","    def _extract_year(self, text):\n","        text = str(text)\n","        # Try extracting year from parentheses\n","        parentheses_match = re.search(r'\\((\\d{4})\\)', text)\n","        if parentheses_match:\n","            return int(parentheses_match.group(1))\n","\n","        # Try extracting year with hyphen\n","        hyphen_match = re.search(r'-(\\d{4})', text)\n","        if hyphen_match:\n","            return int(hyphen_match.group(1))\n","\n","        # Try direct year match\n","        direct_match = re.search(r'\\b(\\d{4})\\b', text)\n","        if direct_match:\n","            return int(direct_match.group(1))\n","\n","        return np.nan\n","\n","    def _encode_categorical(self, series, delimiter=None, top_n=50):\n","        if delimiter:\n","            series = series.str.split(delimiter)\n","\n","        all_categories = series.explode().value_counts()\n","        top_categories = all_categories.head(top_n).index.tolist()\n","        category_mapping = {cat: idx for idx, cat in enumerate(top_categories)}\n","\n","        def encode_entry(entry):\n","            if isinstance(entry, list):\n","                return [category_mapping.get(cat, -1) for cat in entry if cat in category_mapping]\n","            else:\n","                return category_mapping.get(entry, -1)\n","\n","        encoded = series.apply(encode_entry)\n","        return encoded\n","\n","    def preprocess_data(self, df):\n","        # Clean column names\n","        df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n","\n","        # Extract year from movie name\n","        df['year_of_release'] = df['movie_name'].apply(self._extract_year)\n","\n","        # Clean and convert runtime\n","        df['runtime'] = df['runtime'].astype(str)\n","        df['runtime'] = df['runtime'].str.replace(' min', '')\n","        df['runtime'] = pd.to_numeric(df['runtime'], errors='coerce')\n","\n","        # Clean votes\n","        df['no_of_votes'] = df['no_of_votes'].astype(str).str.replace(',', '').str.strip()\n","        df['no_of_votes'] = pd.to_numeric(df['no_of_votes'], errors='coerce')\n","        df['no_of_votes'] = df['no_of_votes'].fillna(0).astype(int)\n","\n","        # Handle missing years\n","        current_year = pd.Timestamp.now().year\n","        df['year_of_release'] = df['year_of_release'].apply(\n","            lambda x: x if pd.notnull(x) and 1900 <= x <= current_year else np.nan\n","        )\n","\n","        median_year = df['year_of_release'].median()\n","        df['year_of_release'] = df['year_of_release'].fillna(median_year)\n","\n","        # Define columns for processing\n","        numeric_columns = ['year_of_release', 'runtime', 'imdb_rating', 'no_of_votes']\n","        text_columns = ['movie_name', 'plot_description', 'director', 'actors']\n","\n","        # Process numeric columns\n","        for col in numeric_columns:\n","            df[col] = pd.to_numeric(df[col], errors='coerce')\n","\n","        numeric_imputer = SimpleImputer(strategy='median')\n","        df[numeric_columns] = numeric_imputer.fit_transform(df[numeric_columns])\n","\n","        # Process text columns\n","        for col in text_columns:\n","            df[col] = df[col].fillna('Unknown')\n","            df[col] = df[col].str.strip()\n","\n","        # Feature engineering\n","        df['runtime_minutes'] = df['runtime'].astype(float)\n","        df['directors_encoded'] = self._encode_categorical(df['director'])\n","        df['actors_encoded'] = self._encode_categorical(df['actors'], delimiter='|')\n","\n","        # Normalize features\n","        scaler = StandardScaler()\n","        df[['normalized_rating', 'normalized_votes']] = scaler.fit_transform(\n","            df[['imdb_rating', 'no_of_votes']]\n","        )\n","\n","        return df\n","\n","    def balance_dataset(self, df):\n","        X = df[['normalized_rating', 'normalized_votes']]\n","        y = df['imdb_rating']\n","\n","        smote = SMOTE(random_state=42)\n","        X_resampled, y_resampled = smote.fit_resample(X, y)\n","\n","        balanced_df = pd.DataFrame(X_resampled, columns=X.columns)\n","        balanced_df['imdb_rating'] = y_resampled\n","\n","        return balanced_df\n","\n"],"metadata":{"id":"X5ucWqWcAfRL","executionInfo":{"status":"ok","timestamp":1732902442515,"user_tz":-330,"elapsed":351,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# Feature Extraction\n","\n","import torch\n","import torch.nn as nn\n","from transformers import AutoModel, AutoTokenizer\n","\n","class TextFeatureExtractor:\n","    def __init__(self, model_name='ai4bharat/indic-bert'):\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n","        self.model = AutoModel.from_pretrained(model_name)\n","\n","    def extract_text_features(self, texts):\n","        inputs = self.tokenizer(\n","            texts,\n","            padding=True,\n","            truncation=True,\n","            max_length=512,\n","            return_tensors='pt'\n","        )\n","\n","        with torch.no_grad():\n","            outputs = self.model(**inputs)\n","\n","        return outputs.last_hidden_state.mean(dim=1)\n","\n","class CNNFeatureExtractor(nn.Module):\n","    def __init__(self, input_dim, embedding_dim):\n","        super().__init__()\n","        self.conv1d = nn.Conv1d(\n","            in_channels=input_dim,\n","            out_channels=embedding_dim,\n","            kernel_size=3,\n","            padding=1\n","        )\n","        self.relu = nn.LeakyReLU()\n","        self.pool = nn.MaxPool1d(kernel_size=2)\n","\n","    def forward(self, x):\n","        x = self.conv1d(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","        return x\n","\n"],"metadata":{"id":"civSvBDaCOGN","executionInfo":{"status":"ok","timestamp":1732902470284,"user_tz":-330,"elapsed":369,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["pip install dgl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vm0yLiHkCh03","executionInfo":{"status":"ok","timestamp":1732902543735,"user_tz":-330,"elapsed":5686,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}},"outputId":"6c7f3ae2-2379-4350-9034-d54fa433e521"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (2.1.0)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.26.4)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.13.1)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.4.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.6)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n","Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.8.30)\n","Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.12.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (3.0.2)\n"]}]},{"cell_type":"code","source":["\n","\n","from neo4j import GraphDatabase\n","import networkx as nx\n","import numpy as np\n","\n","class GraphConstructor:\n","    def __init__(self, config):\n","        self.config = config\n","\n","    def create_movie_graph(self, movies_df):\n","        G = nx.Graph()\n","\n","        for _, movie in movies_df.iterrows():\n","            G.add_node(\n","                movie['movie_name'],\n","                type='movie',\n","                rating=movie['imdb_rating'],\n","                year=movie['year_of_release']\n","            )\n","\n","        similarity_matrix = self._compute_movie_similarity(movies_df)\n","\n","        for i in range(len(movies_df)):\n","            for j in range(i+1, len(movies_df)):\n","                if similarity_matrix[i, j] > self.config.SIMILARITY_THRESHOLD:\n","                    G.add_edge(\n","                        movies_df.iloc[i]['movie_name'],\n","                        movies_df.iloc[j]['movie_name'],\n","                        weight=similarity_matrix[i, j]\n","                    )\n","\n","        return G\n","\n","    def _compute_movie_similarity(self, movies_df):\n","        features = movies_df[['normalized_rating', 'normalized_votes']].values\n","        norm = np.linalg.norm(features, axis=1)\n","        similarity = np.dot(features, features.T) / (norm[:, None] * norm[None, :])\n","        return similarity\n","\n"],"metadata":{"id":"6_Ki8LFUCUVf","executionInfo":{"status":"ok","timestamp":1732902600633,"user_tz":-330,"elapsed":790,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["# Recommendation Engine\n","\n","import numpy as np\n","import networkx as nx\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","class BollywoodRecommender:\n","    def __init__(self, graph, feature_extractor):\n","        self.graph = graph\n","        self.feature_extractor = feature_extractor\n","\n","    def get_recommendations(self, base_movie, top_k=3):\n","        if base_movie not in self.graph.nodes:\n","            raise ValueError(f\"Movie {base_movie} not found in graph\")\n","\n","        content_candidates = self._content_based_recommendation(base_movie)\n","        graph_candidates = self._graph_based_recommendation(base_movie)\n","        recommendations = self._merge_recommendations(\n","            content_candidates,\n","            graph_candidates,\n","            top_k\n","        )\n","\n","        return recommendations\n","\n","    def _content_based_recommendation(self, base_movie):\n","        candidates = {}\n","        for movie in self.graph.nodes:\n","            if movie != base_movie:\n","                similarity = self._compute_content_similarity(base_movie, movie)\n","                candidates[movie] = similarity\n","\n","        return sorted(candidates.items(), key=lambda x: x[1], reverse=True)\n","\n","    def _graph_based_recommendation(self, base_movie):\n","        candidates = {}\n","        for movie in nx.single_source_shortest_path_length(\n","            self.graph, base_movie, cutoff=2\n","        ).keys():\n","            if movie != base_movie:\n","                candidates[movie] = self.graph[base_movie][movie]['weight']\n","\n","        return sorted(candidates.items(), key=lambda x: x[1], reverse=True)\n","\n","    def _merge_recommendations(self, content_candidates, graph_candidates, top_k):\n","        merged_candidates = {}\n","\n","        for movie, score in content_candidates:\n","            merged_candidates[movie] = 0.6 * score\n","\n","        for movie, score in graph_candidates:\n","            merged_candidates[movie] = merged_candidates.get(movie, 0) + 0.4 * score\n","\n","        top_recommendations = sorted(\n","            merged_candidates.items(),\n","            key=lambda x: x[1],\n","            reverse=True\n","        )[:top_k]\n","\n","        return [movie for movie, _ in top_recommendations]\n","\n","    def _compute_content_similarity(self, movie1, movie2):\n","        return cosine_similarity(\n","            self.feature_extractor.extract_text_features([movie1]),\n","            self.feature_extractor.extract_text_features([movie2])\n","        )[0][0]\n","\n"],"metadata":{"id":"FXp6vQokCz9y","executionInfo":{"status":"ok","timestamp":1732902621715,"user_tz":-330,"elapsed":358,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import logging\n","\n","def setup_logging():\n","    logging.basicConfig(\n","        level=logging.INFO,\n","        format='%(asctime)s - %(levelname)s - %(message)s'\n","    )\n","    return logging.getLogger(__name__)\n","\n","def main():\n","    # Initialize configuration and logging\n","    config = Config()\n","    logger = setup_logging()\n","\n","    try:\n","        logger.info(\"Starting Bollywood Movie Recommender System\")\n","\n","        # Initialize data preprocessor and load data\n","        logger.info(\"Loading and preprocessing data...\")\n","        preprocessor = DataPreprocessor(config)\n","        raw_data = preprocessor.load_data()\n","        processed_data = preprocessor.preprocess_data(raw_data)\n","\n","        # Balance dataset if needed\n","        logger.info(\"Balancing dataset...\")\n","        balanced_data = preprocessor.balance_dataset(processed_data)\n","\n","        # Initialize feature extractor\n","        logger.info(\"Initializing feature extraction...\")\n","        feature_extractor = TextFeatureExtractor()\n","\n","        # Construct movie similarity graph\n","        logger.info(\"Constructing movie similarity graph...\")\n","        graph_constructor = GraphConstructor(config)\n","        movie_graph = graph_constructor.create_movie_graph(balanced_data)\n","\n","        # Initialize recommendation engine\n","        logger.info(\"Initializing recommendation engine...\")\n","        recommender = BollywoodRecommender(movie_graph, feature_extractor)\n","\n","        # Save processed data\n","        logger.info(\"Saving processed data...\")\n","        processed_data.to_csv(config.PROCESSED_DATA_PATH, index=False)\n","\n","        return recommender, processed_data\n","\n","    except Exception as e:\n","        logger.error(f\"An error occurred: {str(e)}\")\n","        raise\n","\n","def get_recommendations(recommender, movie_name, top_k=None):\n","    \"\"\"\n","    Get movie recommendations for a given movie.\n","\n","    Args:\n","        recommender: Initialized BollywoodRecommender instance\n","        movie_name (str): Name of the movie to get recommendations for\n","        top_k (int, optional): Number of recommendations to return\n","\n","    Returns:\n","        list: List of recommended movie names\n","    \"\"\"\n","    try:\n","        if top_k is None:\n","            top_k = Config.TOP_K_RECOMMENDATIONS\n","\n","        recommendations = recommender.get_recommendations(movie_name, top_k=top_k)\n","        return recommendations\n","\n","    except ValueError as e:\n","        logging.error(f\"Movie not found: {str(e)}\")\n","        return []\n","    except Exception as e:\n","        logging.error(f\"Error getting recommendations: {str(e)}\")\n","        return []\n","\n","if __name__ == \"__main__\":\n","    # Initialize the system\n","    recommender, processed_data = main()\n","\n","    # Example usage\n","    print(\"\\nBollywood Movie Recommender System\")\n","    print(\"----------------------------------\")\n","\n","    # Get some example movies from the dataset\n","    example_movies = processed_data['movie_name'].head().tolist()\n","\n","    print(\"\\nAvailable movies (sample):\")\n","    for idx, movie in enumerate(example_movies, 1):\n","        print(f\"{idx}. {movie}\")\n","\n","    # Get recommendations for the first movie\n","    if example_movies:\n","        print(f\"\\nGetting recommendations for: {example_movies[0]}\")\n","        recommendations = get_recommendations(recommender, example_movies[0])\n","\n","        print(\"\\nRecommended movies:\")\n","        for idx, movie in enumerate(recommendations, 1):\n","            print(f\"{idx}. {movie}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"3-iU8A9iC5c7","executionInfo":{"status":"error","timestamp":1732902902258,"user_tz":-330,"elapsed":382,"user":{"displayName":"jain pictures","userId":"13221075159637960320"}},"outputId":"52619bb1-71e0-435a-9127-a4284288618e"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:__main__:An error occurred: [Errno 2] No such file or directory: 'data/bollywood_data_set.csv'\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'data/bollywood_data_set.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-62335f4210fe>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# Initialize the system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mrecommender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-63-62335f4210fe>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading and preprocessing data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataPreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-46-f4fcdc06b297>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRAW_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/bollywood_data_set.csv'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1Uw0QRVHC9Ot"},"execution_count":null,"outputs":[]}]}